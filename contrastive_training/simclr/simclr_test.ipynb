{"cells":[{"cell_type":"code","execution_count":1,"id":"17420941","metadata":{},"outputs":[],"source":["import sys\n","sys.path.append(\"../..\")"]},{"cell_type":"code","execution_count":2,"id":"3f6ca90b","metadata":{},"outputs":[],"source":["model_path = '../../trained_models/simclr/'\n","dataset = 'panoptic'"]},{"cell_type":"markdown","id":"91c43fe5","metadata":{},"source":["# Imports"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"411eafd1"},"outputs":[],"source":["import os\n","import torch\n","import re\n","import random\n","from torchvision.io import read_image\n","\n","import matplotlib.pyplot as plt\n","import torchvision.transforms as T"]},{"cell_type":"markdown","metadata":{"id":"9d7173f7"},"source":["## SimCLR method\n","[SimCLR](https://arxiv.org/pdf/2002.05709.pdf) I take the base encoder model (ResNet50) and replace its fully connected layer with a projection head."]},{"cell_type":"code","execution_count":4,"metadata":{"id":"26c96dfe"},"outputs":[],"source":["from contrastive_training.simclr.model import get_simclr_net"]},{"cell_type":"markdown","metadata":{"id":"1851fe11"},"source":["# Clustering"]},{"cell_type":"markdown","metadata":{"id":"3cc5e1e5"},"source":["I extract the representations from the trained model and run K means clustering algorithm (number of clusters=8) on these representation. I reduce the dimentionality of the representations with PCA and LDA algorithm and plot the clustering.\n","For the comparison I use the representations extracted from encoder model (before the projection head) and the representations extracted after the projection head."]},{"cell_type":"markdown","id":"bb608b2c","metadata":{},"source":["## Setup"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"8b62029d"},"outputs":[],"source":["from dataloaders.datasets import cluster_datasets"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"b1a0a90d"},"outputs":[],"source":["def get_cluster_data(batch_size, dataset='panoptic'):\n","    transforms = T.Compose(\n","        [\n","            T.ToTensor(),\n","            T.Resize(size=(128, 128)),\n","        ]\n","    )\n","\n","    cluster_dataset = cluster_datasets[dataset](transforms)\n","    \n","    cluster_loader = torch.utils.data.DataLoader(cluster_dataset, batch_size)\n","\n","    return cluster_dataset, cluster_loader"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"80b3b102"},"outputs":[],"source":["def extract_representations(path, cluster_loader, load=True):\n","    net = get_simclr_net()\n","\n","    if load:\n","        net.load_state_dict(torch.load(path, map_location=torch.device('cpu')))\n","\n","    net.to('cpu')\n","    net.eval()\n","\n","    proj_repr = []\n","    base_repr = []\n","\n","    with torch.no_grad():\n","        for batch_idx, inputs in enumerate(cluster_loader):\n","            images = inputs['image']\n","            images.to('cpu')\n","            base, proj = net(images)\n","            proj_repr.append(proj)\n","            base_repr.append(base)\n","\n","    return torch.cat(base_repr).numpy(), torch.cat(proj_repr).numpy()"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"22307fb9"},"outputs":[],"source":["from sklearn.cluster import KMeans\n","\n","\n","def kmeans_algorithm(features, n_clusters=8):\n","    kmeans = KMeans(n_clusters=n_clusters)\n","    kmeans.fit(features)\n","\n","    return kmeans.labels_"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"614ae399"},"outputs":[],"source":["#import LDA\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n","#import PCA\n","from sklearn.decomposition import PCA\n","\n","def reduce_dim_LDA(features, labels, n_components=2):\n","    lda = LDA(n_components=n_components)\n","    lda.fit(features, labels)\n","\n","    return lda.transform(features)\n","\n","def reduce_dim_PCA(features, n_components=2):\n","    pca = PCA(n_components=n_components)\n","    pca.fit(features)\n","\n","    return pca.transform(features)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"26f9bb8d"},"outputs":[],"source":["def plot_clusters(clusters, features, title):\n","    colors = {\n","        0: '#F8512E', 1: '#F8F82E',\n","        2: '#40F82E', 3: '#2EC1F8',\n","        4: '#6B2EF8', 5: '#D92EF8',\n","        6: '#731642', 7: '#092040'\n","    }\n","\n","    cluster_colors = [colors[c] for c in clusters]\n","\n","    plt.scatter(features[:, 0], features[:, 1], c=cluster_colors)\n","    plt.title(title)\n","    plt.show()"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"51fa29d4"},"outputs":[],"source":["from sklearn.metrics import silhouette_score\n","\n","\n","def cluster(model_path, load=True, n_clusters=8, n_components=2, dataset='panoptic'):\n","    cluster_set, cluster_loader = get_cluster_data(30, dataset)\n","\n","    base_features, proj_features = extract_representations(model_path, cluster_loader, load)\n","\n","    labels_base = kmeans_algorithm(features=base_features, n_clusters=n_clusters)\n","    lda_base = reduce_dim_LDA(features=base_features, labels=labels_base, n_components=n_components)\n","    pca_base = reduce_dim_PCA(features=base_features, n_components=n_components)\n","\n","    labels_proj = kmeans_algorithm(proj_features, n_clusters=n_clusters)\n","    lda_proj = reduce_dim_LDA(features=proj_features, labels=labels_proj, n_components=n_components)\n","    pca_proj = reduce_dim_PCA(features=proj_features, n_components=n_components)\n","\n","    silhouette_base = silhouette_score(base_features, labels_base)\n","    silhouette_proj = silhouette_score(proj_features, labels_proj)\n","\n","    print(\"Silhouette score for the encoder features: {}\".format(silhouette_base))\n","    print(\"Silhouette score for the projection head features: {}\".format(silhouette_proj))\n","\n","    plot_clusters(labels_base, lda_base, \"Encoder features LDA\")\n","    plot_clusters(labels_proj, lda_proj, \"Projection head features LDA\")\n","\n","    plot_clusters(labels_base, pca_base, \"Encoder features PCA\")\n","    plot_clusters(labels_proj, pca_proj, \"Projection head features PCA\")\n","\n","    return cluster_set, base_features, proj_features, labels_base, labels_proj, lda_base, lda_proj, pca_base, pca_proj"]},{"cell_type":"code","execution_count":12,"id":"e0974dde","metadata":{},"outputs":[],"source":["#get the latest model\n","epoch = 0\n","for file in os.listdir(model_path):\n","    if 'simclr_epoch' in file:\n","        e = int(re.findall(r'\\d+', file)[0])\n","        if e > epoch:\n","            epoch = e\n","\n","path = model_path + 'simclr_epoch_{:d}.pth'.format(epoch)\n","\n","#path=\"trained_models/ver1.pt\""]},{"cell_type":"markdown","id":"9e0f84e7","metadata":{"id":"3024983d"},"source":["## Before training"]},{"cell_type":"code","execution_count":13,"id":"8a71f282","metadata":{"id":"edb3de48","outputId":"a40cee51-c5e6-4ed5-e745-328faef6592c","scrolled":false},"outputs":[{"ename":"FileNotFoundError","evalue":"[WinError 3] Impossibile trovare il percorso specificato: 'datasets/ProcessedPanopticDataset/171204_pose3/hdImages'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m _, _, _, _, _, _, _, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mcluster\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_clusters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_components\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[1;32mIn[11], line 5\u001b[0m, in \u001b[0;36mcluster\u001b[1;34m(model_path, load, n_clusters, n_components, dataset)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcluster\u001b[39m(model_path, load\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, n_clusters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpanoptic\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m----> 5\u001b[0m     cluster_set, cluster_loader \u001b[38;5;241m=\u001b[39m \u001b[43mget_cluster_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     base_features, proj_features \u001b[38;5;241m=\u001b[39m extract_representations(model_path, cluster_loader, load)\n\u001b[0;32m      9\u001b[0m     labels_base \u001b[38;5;241m=\u001b[39m kmeans_algorithm(features\u001b[38;5;241m=\u001b[39mbase_features, n_clusters\u001b[38;5;241m=\u001b[39mn_clusters)\n","Cell \u001b[1;32mIn[6], line 9\u001b[0m, in \u001b[0;36mget_cluster_data\u001b[1;34m(batch_size, dataset)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_cluster_data\u001b[39m(batch_size, dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpanoptic\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m      2\u001b[0m     transforms \u001b[38;5;241m=\u001b[39m T\u001b[38;5;241m.\u001b[39mCompose(\n\u001b[0;32m      3\u001b[0m         [\n\u001b[0;32m      4\u001b[0m             T\u001b[38;5;241m.\u001b[39mToTensor(),\n\u001b[0;32m      5\u001b[0m             T\u001b[38;5;241m.\u001b[39mResize(size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m128\u001b[39m)),\n\u001b[0;32m      6\u001b[0m         ]\n\u001b[0;32m      7\u001b[0m     )\n\u001b[1;32m----> 9\u001b[0m     cluster_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mcluster_datasets\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransforms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     cluster_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(cluster_dataset, batch_size)\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cluster_dataset, cluster_loader\n","File \u001b[1;32mc:\\Users\\david\\Documents\\PROGETTI\\SIV\\contrastive_training\\simclr\\../..\\dataloaders\\panoptic.py:106\u001b[0m, in \u001b[0;36mClusterPanopticDataset.__init__\u001b[1;34m(self, transform, data_set)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, transform, data_set\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    102\u001b[0m \n\u001b[0;32m    103\u001b[0m     \u001b[38;5;66;03m# change this to the path where the dataset is stored\u001b[39;00m\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatasets/ProcessedPanopticDataset/171204_pose3/hdImages\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 106\u001b[0m     images \u001b[38;5;241m=\u001b[39m [os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_path, f\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_path\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m    107\u001b[0m                 \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_path, f\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)))][\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m6000\u001b[39m]\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;241m=\u001b[39m transform\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpaths\u001b[39m\u001b[38;5;124m'\u001b[39m: images}\n","\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] Impossibile trovare il percorso specificato: 'datasets/ProcessedPanopticDataset/171204_pose3/hdImages'"]}],"source":["_, _, _, _, _, _, _, _, _ = cluster(path, load=True, n_clusters=8, n_components=2, dataset=dataset)"]},{"cell_type":"markdown","metadata":{"id":"1ac3d405"},"source":["## Trained model\n","visualization based on the model preprained with 0.0001 learning rate for base encoder"]},{"cell_type":"code","execution_count":null,"id":"8d575539","metadata":{},"outputs":[],"source":["cluster_set, base_features, proj_features, labels_base, labels_proj, lda_base, lda_proj, pca_base, pca_proj = cluster(path, load=True, n_clusters=8, n_components=2, dataset=dataset)"]},{"cell_type":"markdown","metadata":{"id":"24516d03"},"source":["### Clustering results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bf44567b"},"outputs":[],"source":["def plot_one_cluster(dataset, cluster_ind, labels):\n","    indexes = [i for i in range(0, len(labels)) if labels[i]==cluster_ind]\n","\n","    plt.figure(figsize = (10,10))\n","\n","    for i in range(0, 9):\n","        ax = plt.subplot(3, 3, i+1)\n","        ax.imshow(dataset[indexes[random.randint(0, len(indexes)-1)]]['image'].permute(1, 2, 0))\n","\n","    plt.show()"]},{"cell_type":"markdown","metadata":{"id":"232accfc"},"source":["#### Base encoder\n","Clustering based on features extracted from base encoder"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2460064e","outputId":"5fc47793-d503-436c-d134-aab81e67fa47","scrolled":false},"outputs":[],"source":["plot_one_cluster(cluster_set, 0, labels_base)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eaf095ba","outputId":"3fda7706-188e-4b17-b585-12cf5951e974","scrolled":false},"outputs":[],"source":["plot_one_cluster(cluster_set, 1, labels_base)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"456efc72","outputId":"5c7be5e7-e0cb-4c5c-a352-d01e95a6da19","scrolled":false},"outputs":[],"source":["plot_one_cluster(cluster_set, 2, labels_base)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"68a91c53","outputId":"207fdc80-d1fe-45c1-fc38-785245fb60f8","scrolled":false},"outputs":[],"source":["plot_one_cluster(cluster_set, 3, labels_base)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"704ceaf0","outputId":"606cf3e9-c838-4fc8-f178-45363fe6b864","scrolled":false},"outputs":[],"source":["plot_one_cluster(cluster_set, 4, labels_base)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1e819374","outputId":"7323525c-6d1e-4161-f68a-7e9c77b057af","scrolled":false},"outputs":[],"source":["plot_one_cluster(cluster_set, 5, labels_base)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3635447a","outputId":"d2d18b71-053d-4038-e83e-1964e46c5e47","scrolled":false},"outputs":[],"source":["plot_one_cluster(cluster_set, 6, labels_base)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"714a3cd8","outputId":"58cc722e-ce61-44e5-9f7d-2089a3d46ce8","scrolled":false},"outputs":[],"source":["plot_one_cluster(cluster_set, 7, labels_base)"]},{"cell_type":"markdown","metadata":{"id":"b22d0eae"},"source":["#### Projection head\n","Clustering based on features extracted from projection head"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"23b89d8c","outputId":"c0e9f70d-7704-488e-ad4a-8222394b714e"},"outputs":[],"source":["plot_one_cluster(cluster_set, 0, labels_proj)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8380f483","outputId":"2c05fa62-64aa-4e41-d150-0586cff400cc"},"outputs":[],"source":["plot_one_cluster(cluster_set, 1, labels_proj)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"68a640b7","outputId":"000fdd8c-adec-4831-88bb-aaec6eb471bd"},"outputs":[],"source":["plot_one_cluster(cluster_set, 2, labels_proj)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"22694c12","outputId":"3e7b6b4f-3228-4875-df30-c12c6c093dbc"},"outputs":[],"source":["plot_one_cluster(cluster_set, 3, labels_proj)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a71fdd0c","outputId":"52c4f152-66b4-4a49-b930-628bc8009c95"},"outputs":[],"source":["plot_one_cluster(cluster_set, 4, labels_proj)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c4928f3d","outputId":"2e9e5464-623b-4c27-d7f4-292019619355"},"outputs":[],"source":["plot_one_cluster(cluster_set, 5, labels_proj)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"84893076","outputId":"89062524-764b-4ab5-c9cf-77daf189a7fd"},"outputs":[],"source":["plot_one_cluster(cluster_set, 6, labels_proj)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dba67919","outputId":"f012ac62-559c-4dc4-927b-b529f80e89bb"},"outputs":[],"source":["plot_one_cluster(cluster_set, 7, labels_proj)"]}],"metadata":{"colab":{"name":"","version":""},"kernelspec":{"display_name":".venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"}},"nbformat":4,"nbformat_minor":5}
